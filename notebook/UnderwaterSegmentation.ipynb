{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Underwater Semantic Segmentation (SUIM) â€“ Assignment 2 Proposal 6\n",
        "Custom UNet-ResAttn + baselines SUIM-Net and DeepLabV3.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, sys\n",
        "sys.path.append('..')\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datasets.suim_dataset import SUIMDataset, CLASS_NAMES\n",
        "from datasets.augmentations import train_transforms, val_transforms\n",
        "from models.unet_resattn import UNetResAttn\n",
        "from models.suimnet import SUIMNet\n",
        "from models.deeplab_resnet import get_deeplabv3\n",
        "from training.loss import DiceCELoss\n",
        "from training.train import train_one_epoch, validate\n",
        "from training.eval import evaluate_loader\n",
        "from training.utils import count_parameters, save_checkpoint\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create / Check Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "No images found in data/images",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownload_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_splits\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(\u001b[33m'\u001b[39m\u001b[33mdata/splits/train.txt\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mcreate_splits\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/images\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/splits\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mSplits OK\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CV_Assign2/notebook/../data/utils/download_data.py:27\u001b[39m, in \u001b[36mcreate_splits\u001b[39m\u001b[34m(images_dir, out_dir, train_ratio, val_ratio, seed)\u001b[39m\n\u001b[32m     25\u001b[39m images = \u001b[38;5;28msorted\u001b[39m([p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m Path(images_dir).glob(\u001b[33m\"\u001b[39m\u001b[33m*.jpg\u001b[39m\u001b[33m\"\u001b[39m)])\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(images) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo images found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimages_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m ids = [p.stem \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[32m     30\u001b[39m random.Random(seed).shuffle(ids)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: No images found in data/images"
          ]
        }
      ],
      "source": [
        "from data.utils.download_data import create_splits\n",
        "if not os.path.exists('data/splits/train.txt'):\n",
        "    create_splits('data/images', 'data/splits')\n",
        "print('Splits OK')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/splits/train.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_ds = \u001b[43mSUIMDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/splits/train.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_transforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m val_ds   = SUIMDataset(\u001b[33m'\u001b[39m\u001b[33mdata/splits/val.txt\u001b[39m\u001b[33m'\u001b[39m, transform=val_transforms)\n\u001b[32m      3\u001b[39m test_ds  = SUIMDataset(\u001b[33m'\u001b[39m\u001b[33mdata/splits/test.txt\u001b[39m\u001b[33m'\u001b[39m, transform=val_transforms)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CV_Assign2/notebook/../datasets/suim_dataset.py:87\u001b[39m, in \u001b[36mSUIMDataset.__init__\u001b[39m\u001b[34m(self, split_file, images_dir, masks_dir, transform, merge_classes)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m.transform = transform\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.merge_classes = merge_classes\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     88\u001b[39m     \u001b[38;5;28mself\u001b[39m.ids = [line.strip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f \u001b[38;5;28;01mif\u001b[39;00m line.strip()]\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/splits/train.txt'"
          ]
        }
      ],
      "source": [
        "train_ds = SUIMDataset('data/splits/train.txt', transform=train_transforms)\n",
        "val_ds   = SUIMDataset('data/splits/val.txt', transform=val_transforms)\n",
        "test_ds  = SUIMDataset('data/splits/test.txt', transform=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(test_ds, batch_size=4, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train Custom UNet-ResAttn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = UNetResAttn().to(device)\n",
        "criterion = DiceCELoss(dice_weight=0.5)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "print('Params:', count_parameters(model)/1e6, 'M')\n",
        "\n",
        "best_iou = 0\n",
        "history = {'train_loss':[], 'val_loss':[], 'train_iou':[], 'val_iou':[]}\n",
        "for epoch in range(40):\n",
        "    tr_loss, tr_iou = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "    va_loss, va_iou = validate(model, val_loader, criterion, device)\n",
        "    history['train_loss'].append(tr_loss)\n",
        "    history['val_loss'].append(va_loss)\n",
        "    history['train_iou'].append(tr_iou)\n",
        "    history['val_iou'].append(va_iou)\n",
        "    if va_iou > best_iou:\n",
        "        best_iou = va_iou\n",
        "        save_checkpoint(model, optimizer, epoch, best_iou, 'results/checkpoints/unet_resattn_best.pth')\n",
        "    print(f'Epoch {epoch:02d} | tr IoU={tr_iou:.3f} va IoU={va_iou:.3f} tr loss={tr_loss:.3f} va loss={va_loss:.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluate on Test Set (Custom Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_miou, test_per_class = evaluate_loader(model, test_loader, device)\n",
        "print('Test mIoU:', test_miou)\n",
        "for name, v in zip(CLASS_NAMES, test_per_class):\n",
        "    print(name, v)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. SUIM-Net baseline (train similarly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "suim_model = SUIMNet().to(device)\n",
        "print('Params:', count_parameters(suim_model)/1e6, 'M')\n",
        "# Train with same loop if you want fair comparison.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. DeepLabV3 baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deeplab = get_deeplabv3(num_classes=8, pretrained=True).to(device)\n",
        "print('Params:', count_parameters(deeplab)/1e6, 'M')\n",
        "# deeplab(x) returns {'out': logits}\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
